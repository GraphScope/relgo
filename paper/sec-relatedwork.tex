\section{Related Work}
\label{sec:related-work}
%\textit{GetVertex}, \textit{GetEdge}, and \textit{GetNeighbor} are commonly used in graph queries.
%Specifically, \textit{GetVertex} is used to get the adjacent vertices of an edge, \textit{GetEdge} returns the edges from or to a given vertex, and \textit{GetNeigbor} gets the neighbors of a given vertex.
%Based on SQL/PGQ, in relational database, these operators can be implemented by joining tables representing vertices and edges.
%Then, it is crucial to support efficient join order optimization in the converged graph relational optimizer.

%In this section, we survey the query optimization techniques for relational databases and graph databases, respectively.
%Moreover, the mapping between relational data model and property graph
%Moreover, some relational databases (e.g., Oracle) allow users to create graph indices on relational tables.
%Then, researchers study to improve the performances of query execution with such graph indices.
%Therefore, this kind of works are also included in this section.
%These two types of works are also included in this section.

\stitle{Query Optimization for Relational Databases.} Join order optimization was a traditional and crucial topic for query optimization in relational databases. The order in which joins were conducted could influence the execution time significantly and had attained substantial accomplishments. Various studies of query optimization for relational databases were proposed to find the optimal join order. 
Ibaraki et al.\cite{nested-tods-1984} proved the NP-complexity of the join order optimization problem and designed an efficient algorithm with a time complexity of $O(n^2logn)$ to optimize tree queries. 
%Ibaraki et al.\cite{nested-tods-1984} proposed that there were usually fewer than ten tables involved in a typical query, and dealt with joins using nested-loops join. Specifically, they proved the NP-complexity of the join order optimization problem and designed an efficient algorithm with a time complexity of $O(n^2logn)$ to optimize tree queries. 
Then, Krishnamurthy et al.\cite{optimize-nested-vldb-1986} optimized the algorithm and proposed an algorithm with a time complexity of $O(N^2)$ by reusing the computation results. 
%Besides, the authors emphasized that since finding the optimal join order was a complex problem, it was more important to avoid the worst plan. 
Moreover, Haffner et al.\cite{astarjoin} converted the problem of join order optimization to that of finding the shortest path on directed graphs and solved the problem with the A* algorithm. In detail, four heuristics were designed to estimate the remaining cost. Furthermore, Kossmann et al.\cite{data-dependency-join} summarized the methods to optimize queries with data dependencies, such as uniqueness constraints, foreign key constraints, and inclusion dependencies.
All relational optimizations can be orthogonally adopted in \name's relational optimizer.

%Several studies have focused on improving cardinality estimation for cost computation, enabling cost-based optimizers to search for execution plans with potentially lower costs. A common approach is to estimate cardinality through sampling \cite{index-based-join-sampling,ripple-join,wanderjoin,index-based-join-sampling}. For instance, Li et al.\cite{wanderjoin} present an unbiased estimator based on random walks to estimate cardinalities. Leis et al.\cite{index-based-join-sampling} propose a computationally inexpensive method called index-based join sampling to improve accuracy. Other studies estimate cardinalities using histograms \cite{histogram,postgres-row-estimation}. These methods divide the values of a table column into several buckets to build a histogram and assume that the values are uniformly distributed within each bucket. The cardinality is then estimated by summing the number of values in the relevant buckets. Additionally, learning-based methods have been explored for cardinality estimation \cite{learning-based-estimation-1,learning-based-estimation-2,learning-based-estimation-3,learning-based-estimation-4}.


\comment{
Some researchers \cite{selinger,postgres-row-estimation} estimate the number of cardinalities by computing the selectivity of $A \bowtie_{A.col_1 = B.col_2} B$ as
\begin{equation*}
    \frac{1}{max(DV(A.col_1), DV(B.col_2))},
\end{equation*}
where $DV(A.col_1)$ is the number of distinct values of $A.col_1$ in table $A$.
}


\stitle{Query Optimization for Graph Databases.} Graph pattern matching, a fundamental problem in graph query processing, has been extensively studied~\cite{angles2017foundations}. In sequential settings, Ullmann's backtracking algorithm~\cite{ullmann1976algorithm} has been optimized using various techniques, such as tree indexing~\cite{shang2008quicksi}, symmetry breaking~\cite{han13turbo}, and compression~\cite{bi2016efficient}. However, due to the challenges in parallelizing backtracking algorithms, join-based algorithms have been developed for distributed environments. These algorithms use cost estimation to optimize join order, with binary-join algorithms\cite{lai2015scalable, lai2019distributed} estimating costs using random graph models and worst-case-optimal join algorithms~\cite{ammar2018distributed} ensuring a worst-case upper bound on the cost. Hybrid approaches\cite{mhedhbi2019optimizing, huge} adaptively select between binary and worst-case optimal joins based on the lower cost. Recent studies have focused on improving cost estimation in graph pattern matching, including decomposing graphs into star-shaped subgraphs~\cite{cset}, estimating costs based on nested loop iterations~\cite{AutoMine}, and comparing different cardinality estimation methods~\cite{gcare}. Some optimizers, like GLogS~\cite{GLogS}, search for the optimal plan by representing edges as binary joins or extension subtasks and computing the plan bottom-up to obtain a worst-case optimal plan.
We follow the join-based methods such as~\cite{huge,GLogS} due to their compatibility with the relational context for which \name~ is designed. %However, to ensure seamless integration with the relational environment, we need to make adaptations to these methods accordingly.


\stitle{Bridging Relational and Graph Models.} There is a growing interest in studying the interaction between relational and graph models. Index-based methods, such as GQ-Fast \cite{gqfast} and GrainDB \cite{graindb}, work towards construct graph-like index on relational databases to improve the performance of join execution. \name leveraged GrainDB's indexing technique for implementing physical graph operations. In contrast, methods like GRFusion \cite{GRFusion} and Gart~\cite{gart} work towards materializing graph from the relational tables,
so that graph queries can be executed directly on the materialized graph. Such methods incur additional storage costs and potential inconsistencies between relational and graph data.
We prefer index-based techniques over materialization techniques for due to their ability to work seamlessly with relational databases. % GRFusion builds an in-memory graph view based on relational tables and supports queries on both tables and graph views. This allows some relational joins to be replaced with graph traversals, enabling the application of graph-level optimizations. Similarly, in the work of Gart, the authors develop ETL tools to convert and import relational data into a graph store, upon which any graph processing system can be plugged in for efficient graph analysis. We prefer index-based techniques over materialization techniques due to their ability to work directly with relational databases, avoid additional storage costs, and ensure consistency between relational and graph data, making them more suitable for the relational context in which \name operates.



%In terms of translation-based methods, Apache/Age \cite{apache-age} is a typical work.
%Apache/Age is an extension of PostgreSQL, and it provides the ability to handle hybrid queries including openCypher and SQL.
%In detail, after a graph is created, a namespace with the same name as the graph is created.
%The vertices and edges in the graph are stored in corresponding tables in the namespace.
%When a query with both openCypher and SQL statements is performed, Apache/Age transforms the openCypher statements and converts the operators to those in PostgreSQL (e.g., MATCH PATH $\rightarrow$ join), and then the query is solved by PostgreSQL.
%It seems that Apache/Age is more like a syntactic sugar, and the advantanges of graphs and graph optimizers are not utilized.

%In terms of index-based methods, these methods build graph indices on relational databases, and attempt to accelerate queries with the indices.



\section{Related Work}
\label{sec:related-work}
%\textit{GetVertex}, \textit{GetEdge}, and \textit{GetNeighbor} are commonly used in graph queries.
%Specifically, \textit{GetVertex} is used to get the adjacent vertices of an edge, \textit{GetEdge} returns the edges from or to a given vertex, and \textit{GetNeigbor} gets the neighbors of a given vertex.
%Based on SQL/PGQ, in relational database, these operators can be implemented by joining tables representing vertices and edges.
%Then, it is crucial to support efficient join order optimization in the converged graph relational optimizer.
 
In this section, we first summarize the previous studies of query optimizations for relational databases and graph databases, respectively.
Moreover, some relational databases (e.g., Oracle) allow users to create graph indices on relational tables.
Then, researchers study to improve the performances of query execution with such graph indices.
Therefore, this kind of works are also included in this section.
%These two types of works are also included in this section.

\subsection{Query Optimization for Relational Databases}
\label{sec:related-work:ropt}
Join order optimization is a traditional and crucial topic for query optimization in relational databases.
The order that joins are conducted can influence the execution time significantly and has attained substantial accomplishments.
Various studies of query optimization for relational databases have been proposed to find the optimal join order.
Ibaraki et al.~\cite{nested-tods-1984} propose that there are usually fewer than ten tables involved in a typical query, and deal with joins with nested-loops join.
Specifically, they prove the NP-complexity of the join order optimization problem, and design an efficient algorithm with a time complexity of $O(n^2logn)$ to optimize tree queries.
Then, Krishnamurthy et al.~\cite{optimize-nested-vldb-1986} optimize the algorithm, and propose an algorithm with time complexity of $O(N^2)$ by reusing the computation results.
Besides, the authors emphasize that since finding the optimal join order is a complex problem, it is more important to avoid the worst plan.
Moreover, Haffner et al.~\cite{astarjoin} convert the problem of join order optimization to that of finding the shortest path on directed graphs, and solve the problem with the A* algorithm.
In detail, four heuristics are designed to estimate the remaining cost.
Furthermore, Kossmann et al.~\cite{data-dependency-join} summarize the methods to optimize queries with data dependencies.
For example, given two tables $T_1$ and $T_2$, if the values of attribute $A_1$ on $T_1$ are unique, then the inner-join in queries like 
\begin{lstlisting}
    SELECT T2.A2 FROM T1, T2
    WHERE T1.A1 = T2.A2;
\end{lstlisting}
may be converted into a semi-join, which is more efficient.


Some other studies find better plans by estimating cardinalities more accurately.
A typical method is to estimate the number of cardinalities with sampling \cite{index-based-join-sampling,ripple-join,wanderjoin,index-based-join-sampling}.
Specifically, Li et al.~\cite{wanderjoin} present an unbiased estimator based on random walk to estimate the cardinalities.
Leis et al.~\cite{index-based-join-sampling} propose a cheap method, i.e., index-based join sampling, to improve the accuracy.
Some researchers \cite{selinger,postgres-row-estimation} estimate the number of cardinalities by computing the selectivity of $A \bowtie_{A.col_1 = B.col_2} B$ as 
\begin{equation*}
    \frac{1}{max(DV(A.col_1), DV(B.col_2))},
\end{equation*}
where $DV(A.col_1)$ is the number of distinct values of $A.col_1$ in table $A$.
Besides, some studies estimate the number of cardinalities with histograms \cite{histogram,postgres-row-estimation}.
These methods split the values of a table column into several buckets to build a histogram, and assume that the values are uniformly distributed in each bucket.
Then, the cardinality is estimated by summing up the numbers of values in the related buckets.
Moreover, there are also studies estimating cardinalities with learning-based methods \cite{learning-based-estimation-1,learning-based-estimation-2,learning-based-estimation-3,learning-based-estimation-4}.


\subsection{Query Optimization for Graph Databases}
\label{sec:related-work:gopt}
Subgraph matching is a common and important query in graph databases.
Given a pattern graph, subgraph matching query is to find subgraphs of the data graph that is isomorphic/homomorphic to the pattern graph.
In this process, good orders of matching nodes and edges are essential for efficiently executing the queries.
Please note that when relational tables are considered to represent nodes and edges in graphs, finding a good order of matching nodes and edges is akin to find an efficient join order.
Therefore, the optimization methods in graph databases are instructive for relational databases.

Recently, some studies have been conducted to estimate cardinalities in the process of subgraph matching for a better matching order, and therefore, a better execution plan.
In detail, 
C-Set \cite{cset} decomposes the query graph and the data graph into star-shaped subgraphs, and constructs characteristic sets to estimate.
AutoMine \cite{AutoMine} proposes to estimate the cost of a plan for subgraph matching with the number of iterations in the nested loop.
DecoMine \cite{DecoMine} improves the method of AutoMine and presents an approximate-mining based cost model to estimate the costs of nested loops.
Then, DecoMine finds the optimal abstract syntex tree with the smallest cost.
GLogS \cite{GLogS} proposes a graph optimizer named GLogue to search for the optimal plan.
In GLogue, an edge can represent a binary join or a subtask of an extension, and please note that an extension can be regarded as a set of joins.
GLogue computes the optimal plan in a bottom-up manner, and can efficiently obtain a worst-case optimal plan.
Besides, G-CARE \cite{gcare} compares the performances of different methods for cardinality estimation.

\subsection{Query Optimization for Relational Databases with Graph Indices}
\label{sec:related-work:ropt-gopt}
Recently, researchers have attempted to incorporate the advantages of graph processing into query optimization for relational databases.
The core issue of their studies lies in building graph indices on relational databases, which is similar to the idea of SQL/PGQ.
In this subsection, we summarize these studies. 


%In terms of translation-based methods, Apache/Age \cite{apache-age} is a typical work.
%Apache/Age is an extension of PostgreSQL, and it provides the ability to handle hybrid queries including openCypher and SQL.
%In detail, after a graph is created, a namespace with the same name as the graph is created.
%The vertices and edges in the graph are stored in corresponding tables in the namespace.
%When a query with both openCypher and SQL statements is performed, Apache/Age transforms the openCypher statements and converts the operators to those in PostgreSQL (e.g., MATCH PATH $\rightarrow$ join), and then the query is solved by PostgreSQL.
%It seems that Apache/Age is more like a syntactic sugar, and the advantanges of graphs and graph optimizers are not utilized.

%In terms of index-based methods, these methods build graph indices on relational databases, and attempt to accelerate queries with the indices.
Specifically, GRFusion \cite{GRFusion} builds a graph view in main-memory based on the relational tables, and supports queries on both tables and graph views.
Then, some relational joins can be replaced with graph traversals, and some graph-level optimizations can be applied.
GQ-Fast \cite{gqfast} is proposed to deal with relationship queries, and works accompanying with traditional relational databases.
In GQ-Fast, indices with lookup data structure are built to accelerate.
Given a SQL query, GQ-Fast generates physical plans by transforming relationship query normalized algebra expressions with a Physical-plan Producer, and more optimizations for the plans are necessary.
GrainDB \cite{graindb} builds RID indices, and presents two new join methods (i.e., sip-join and merged-sip-join) that utilize the RID indices to get the adjacent edges and one-hop neighbors of vertices and adjacent vertices of edges efficiently. 
Based on these join methods, in some settings, the cost of multiple join can be reduced significantly.
However, GrainDB inherits the optimizer of DuckDB, and replaces some hash joins with sip-joins and merged-sip-joins directly after the phyical plan is generated.
After such replacement, the cost of the obtained plan is actually unknown.
Therefore, the obtained plan is likely to be suboptimal and the best plan can be missed.

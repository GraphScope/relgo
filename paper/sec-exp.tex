\section{Evaluation}
The experiental results are presented and analyzed in this section.
In detail, experimental settings are introduced in Sec.~\ref{sec:experiment-settings}.
Sec.~\ref{sec:experiment-e2e}-Sec.~\ref{sec:experiment-case-study} conduct the experiments.

\begin{table}[t]
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
    Dataset & |V| & |E| & Disk Space Usage\\ 
    \hline
    $G_{sf10}$& 29,987,835 & 88,317,856 & 8.9G \\
    \hline
    $G_{sf30}$ & 88,789,833 & 278,652,443 & 28.0G\\
    \hline
    $IMDB$ & 14,431,946 & 59,758,241 & 3.7G \\
    \hline
    \end{tabular}
    \caption{Statistics of the datasets. In detail, $|\cdot|$ represents the number of elements in $\cdot$.}
    \label{table:experiment-datasets}
\end{table}

\subsection{Expermental Settings}
\label{sec:experiment-settings}

\textbf{Benchmarks.} In the experiments, two commonly-used benchmarks are leveraged.
The first is the Linked Data Benchmark Council Social Network Benchmark (abbr.~LDBC-SNB or SNB).
For this benchmark, two datasets, i.e., $G_{sf10}$ and $G_{sf30}$ generated with scale factor 10 and 30 respectively, are utilized.
These datasets are mainly about the relationships among persons, forums, posts, comments, locations, and tags.
The queries performed on these datasets are from the LDBC Interactive Complex workloads.
Since we focus on the proving the superiority of the converged optimizer compared to the existing optimzers, we simplify the queries and modify the queries following the experiments of GrainDB \cite{graindb}.
That is, queries IC-10, IC-13, and IC-14 are dropped, and queries containing variable-length joins are broken down into several individual queries, with each one featuring a join along a path with a fixed length.
Specifically, IC-5-2 represents a query obtained by modifying IC-5, and 2 is th length of the path.
The obtained modified benchmark is denoted by SNB-M and queries performed on $G_{sf10}$ and $G_{sf30}$ are from SNB-M.

The other benchmark is Join Order Benchmark (JOB) on Internet Movie Database (abbr.~IMDB).
Specifically, IMDB is a dataset mainly about the relationships among movies, persons, and movie companies.
JOB focuses on the problem of join order optimization, and queries in JOB have an average of 8 joins.
The details of the datasets are summarized in Table \ref{table:experiment-datasets}, where |V| and |E| represent the number of vertices and edges in the datasets, respectively.
For IMDB, its tables are regarded as vertices or edges first, and then the number of vertices and edges are counted.

\textbf{Baselines. }
In the experiments, two optimizers of type $Rel$ and $Rel^+$ respectively are utilized as the baselines.
Specifically, the opitmizer of type $Rel$ is that of DuckDB, which is a well-known open-source database.
The version of DuckDB is 0.9.2.
The optimizer of type $Rel^+$ is that of GrainDB.
It optimizes queries with the optimizer of DuckDB first, and then replaces some hash joins in the obtained physical plans with sip joins or merge sip joins.
To ensure the fairness of the comparison, we first upgrade the version of DuckDB that is integrated into GrainDB to 0.9.2.
Then, given a query, after a physical plan w.r.t.~this query is obtained by an optimizer, the plan is transformed to that of GrainDB.
Therefore, different plans can be executed by the the backend, and the efficiency of the plans obtained by varied optimizers can be compared fairly.
Please note that codegen techniques can be employed to facilitate the transformation of the physical plan.
For simplicity, in the rest of this paper, when there is no ambiguity, the optimizers of DuckDB and GrainDB are shortened to DuckDB and GrainDB, respectively.

Our experiments are carried out on a server with Intel Xeon E5-2682 2.50GHz CPU and 251GB RAM.

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/e2e_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-e2e-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/e2e_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-e2e-sf30}
    \end{subfigure}
    \begin{subfigure}[b]{0.6\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/e2e_job.pdf}
        \caption{Time Cost on IMDB.}
        \label{fig:exp-e2e-job}
    \end{subfigure}
    \caption{Results of the end-to-end experiments.}
    \label{fig:exp-e2e}
\end{figure*}

\subsection{End-to-End Experiments}
\label{sec:experiment-e2e}

End-to-end experiments are conducted on SNB-M and JOB benchmarks to compare the performances of execution plans obtained by DuckDB, GrainDB, and relgo.
For experments on the LDBC benchmark, each IC query is executed for 50 times with different times, and the average time cost is reported.
The exeprimental results are shown in Fig.~\ref{fig:exp-e2e}.

The results demonstrate that the execution plans obtained with relgo are always better than those obtained with GrainDB and DuckDB.
For example, when query 1a is queried on the IMDB dataset, executing the plan from relgo is about 6$\times$ and 10$\times$ faster than executing the plans from GrainDB and DuckDB, respectively.
There are mainly two reasons for the superiority of relgo.
Firstly, relgo is aware of the existence of graph indices in graph query optimization.
Thus, the cost estimation of rego is more accurate and better physical plans can be obtained.
In contrast, the optimizers of DuckDB and GrainDB are of the types $Rel$ and $Rel^+$, respectively, and are not aware of the graph indices in query optimization.
Therefore, the accuracy of cost estimation is limited.
Secondly, for queries with cycles (e.g., IC7-1 on SNB-M), relgo can replace multiple joins with extend-intersection.
Such an operator can significantly reduce the time consumption, which is demonstrated through experiments in Sec.~\ref{sec:experiment-circle}.
Thirdly, relgo is more adept at identifying opportunities to effectively utilize graph indices to get neighbors of vertices, since it optimizes graph queries from the graph perspective.
Conversely, GrainDB occasionally partitions the process into separate stages, first retrieving adjacent edges and subsequently obtaining the corresponding endpoints.


\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/pattern-triangle.png}
        \caption{Triangle}
        \label{fig:exp-hard-triangle}
    \end{subfigure}
    \begin{subfigure}[b]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/pattern-butterfly.png}
        \caption{Butterfly}
        \label{fig:exp-hard-butterfly}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/pattern-clique.png}
        \caption{4-Clique}
        \label{fig:exp-hard-clique}
    \end{subfigure}
    \caption{Patterns searched for in case studies.}
    \label{fig:exp-hard-patterns}
\end{figure}

\subsection{Queries with Circles}
\label{sec:experiment-circle}

In this section, to highlight the strengths our converged optimizer, i.e., relgo, we design three SQL/PGQ queries to find the patterns shown in Fig.~\ref{fig:exp-hard-patterns} on $G_{sf10}$ and $G_{sf30}$.
Take finding 4-cliques as an example, the corresponding SQL/PGQ query is as follows:
\begin{lstlisting}
    SELECT pn1, pn2, pn3, pn4 
    FROM GRAPH_TABLE (knows_grpah
        MATCH (p1:Person)-[:Knows]->(p2:Person)-[:Knows]->(p3:Person)-[:Knows]->(p4:Person),
            (p4)-[:Knows]->(p1)-[:Knows]->(p3),
            (p2)-[:Knows]->(p4)
        COLUMNS (
            p1.id as pn1, p2.id as pn2, 
            p3.id as pn3, p4.id as pn4
        )
    );
\end{lstlisting}
With these three queries, the efficiency of the physical plans obtained by relgo and those obtained by GrainDB are compared.
The experimental results are shown in Fig.~\ref{fig:exp-hard}.


\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/hard_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-hard-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/hard_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-hard-sf30}
    \end{subfigure}
    \caption{Experiments on the time cost of finding patterns in Fig.~\ref{fig:exp-hard-patterns} on $G_{sf10}$ and $G_{sf30}$.}
    \label{fig:exp-hard}
\end{figure}

The experimental results indicate the superiority of relgo compared with GrainDB.
In detail, the physical plans obtained by relgo are always much better than those obtained by GrainDB.
Under the best conditions, i.e., the 4-clique pattern queried on $G_{sf30}$, the execution time of the plan optimized with relgo can be more than an order of magnitude shorter than that of GrainDB.
Such a significant improvement comes from relgo's more accurate estimation of cost, and a better plan can be generated.
Besides, \expandintersectrule can be utilized in the plan generated with relgo, and it is much more efficient than performing multiple joins [as illustrated in Sec.~\ref{sec:experiment-ablation}].



\subsection{Ablation Study}
\label{sec:experiment-ablation}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/ablation_ei_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-ablation-ei-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/ablation_ei_sf10.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-ablation-ei-sf30}
    \end{subfigure}
    \caption{Abaltion study on \expandintersectrule. Please note that executing plans obtained with "Relgo w.o. EI" to find bufferflies and 4-cliques triggers an ``Out of Memory'' (abbr.~OOM) error.}
    \label{fig:exp-ablation-ei}
\end{figure}

In this section, we conduct ablation study to show the efficiency of \expandintersectrule.
In detail, patterns in Fig.~\ref{fig:exp-hard-patterns} are queried on $G_{sf10}$ and $G_{sf30}$, and plans are optimized with Relgo.
For each plan optimized by Relgo, we replace the extend-intersect operators in it with multiple join operators and obtain a new plan.
These new plans are called obtained with \textit{"Relgo w.o. EI"}.
The experimental results are shown in Fig.~\ref{fig:exp-ablation-ei}.

The results illustrate the efficiency of \expandintersectrule.
When triangles are searched for, removing the extend-intersect operators decreases the query performance.
Besides, when butterflies and 4-cliques are searched for, the plans without extend-intersect operators have an excessive memory overhead and cause an ``Out of Memory'' (abbr.~OOM) error.
The reason is that applying extend-intersect operators has much fewer intermediate results than applying multiple joins, since numerous results that will not appear in the intersection are prematurely deleted.
It indicates that \expandintersectrule can not only enhance query performance, but also reduce spatial overhead.

To further demonstrates the efficiency of using \expandintersectrule, we add predicates on butterflies (i.e., Fig.~\ref{fig:exp-hard-butterfly}) and 4-cliques (i.e., Fig.~\ref{fig:exp-hard-clique}) to avoid OOM.
Specifically, for these two patterns, the values of properties Person1.\textit{p\_personid} are constrained to be smaller than specified values.
The results on the constrained-patterns are shown in Fig.~\ref{}.


The results suggest that \expandintersectrule is crucial in optimizing queries with cycles.
Specifically, for all the three patterns with cycles, the execution time of plans optimized by relgo is shorter than those optimized by \textit{"Relgo w.o. EI"}.
It indicates the effectiveness of \expandintersectrule.
Moreover, when patterns with many cycles are used (e.g., 4-clique in Fig.~\ref{fig:exp-hard-clique}), the optimization effect of the rule becomes particularly noticeable.
In detail, querying for 4-cliques with relgo can be 100$\times$ faster than with \textit{"Relgo w.o. EI"}.
The results illustrate the efficiency of \expandintersectrule.


\subsection{Detailed Evaluation}
\label{sec:experiment-detail}

time cost of index building
compilation
query execution

\subsection{Optimization Efficiency Evaluation}
\label{sec:experiment-optimize}

In this subsection, experiments are conducted to compare the optimization time cost of relgo and Apache Calcite, which is a well-known data management framework widely used in various projects such as Hive and Kylin.
Please note that the codes of relgo and Calcite are both written in Java.
In detail, we test the optimization time of relgo and Calcite on SNB-M and JOB benchmarks, and VolcanoPlanner of Calcite with default rules is leveraged.
If optimization for a query is not finished in 10 minutes, the process is early stopped and the time cost of such optimization is recorded as 10 minutes.
The results are shown in Fig.~\ref{fig:exp-optimization}.

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/optimization_sf10.pdf}
        \caption{Optimization Time Cost on $G_{sf10}$.}
        \label{fig:exp-optimization-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/optimization_sf30.pdf}
        \caption{Optimization Time Cost on $G_{sf30}$.}
        \label{fig:exp-optimization-sf30}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/optimization_job.pdf}
        \caption{Optimization Time Cost on IMDB.}
        \label{fig:exp-optimization-job}
    \end{subfigure}
    \caption{Experiments on the time cost of optimization.}
    \label{fig:exp-optimization}
\end{figure*}

In the experiments, optimizing all the queries with relgo can be finished in 10 minutes, while optimizing some queries with Calcite exceeds the 10-minute limit.
For example, when JOB benchmark is utilized, the time cost of optimizing all the queries with Calcite is longer than 10 minutes.
As shown in Fig.~\ref{fig:exp-optimization}, relgo is much more efficient than Calcite in optimizing queries, and it is consistent with the conclusions obtained in Sec.~\ref{sec:theoretical-analysis}.
That is, relgo is exponentially faster than Calcite in query optimization.
For instance, when IC5-1 is queried on $G_{sf30}$, the time cost of query optimization with relgo can be more than $10^4\times$ faster than that of Calcite.

Besides, the optimization time cost of relgo is similar on $G_{sf10}$ and $G_{sf30}$, and so is Calcite.
The reason is that the time required for optimization is not significantly associated with the scale of the dataset; instead, it is related to the relative cardinalities among the different tables.
The relative cardinalities in LDBC datasets of different scales are consistent, therefore the optimization time is similar.



\subsection{Case Study}
\label{sec:experiment-case-study}



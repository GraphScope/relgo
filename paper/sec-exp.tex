\section{Evaluation}
The experiental results are presented and analyzed in this section.
In detail, experimental settings are introduced in Sec.~\ref{sec:experiment-settings}.
Sec.~\ref{sec:experiment-e2e}-Sec.~\ref{sec:experiment-case-study} conduct the end-end experiments, test on queries with cycles, perform ablation studies, evaluate the optimization efficiency, test the efficiency of optimziations accross relational and graph queries, and evaluate the efficiency of the join order of the plans generated by relgo, respectively.

\begin{table}[t]
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
    Dataset & |V| & |E| & Disk Space Usage\\ 
    \hline
    $G_{sf10}$& 29,987,835 & 88,317,856 & 8.9G \\
    \hline
    $G_{sf30}$ & 88,789,833 & 278,652,443 & 28.0G\\
    \hline
    $IMDB$ & 14,431,946 & 59,758,241 & 3.7G \\
    \hline
    \end{tabular}
    \caption{Statistics of the datasets. In detail, $|\cdot|$ represents the number of elements in $\cdot$.}
    \label{table:experiment-datasets}
\end{table}

\subsection{Expermental Settings}
\label{sec:experiment-settings}

\textbf{Benchmarks.} In the experiments, two commonly-used benchmarks are leveraged.
The first is the Linked Data Benchmark Council Social Network Benchmark (abbr.~LDBC-SNB or SNB) \cite{ldbc_snb}.
For this benchmark, two datasets, i.e., $G_{sf10}$ and $G_{sf30}$ generated with scale factor 10 and 30 respectively, are utilized.
These datasets are mainly about the relationships among persons, forums, posts, comments, locations, and tags.
The queries performed on these datasets are from the LDBC Interactive Complex workloads.
Since we focus on the proving the superiority of the converged optimizer compared to the existing optimzers, we simplify the queries and modify the queries following the experiments of GrainDB \cite{graindb}.
That is, queries IC-10, IC-13, and IC-14 are dropped, and queries containing variable-length joins are broken down into several individual queries, with each one featuring a join along a path with a fixed length.
Specifically, IC-5-2 represents a query obtained by modifying IC-5, and 2 is th length of the path.
The obtained modified benchmark is denoted by SNB-M and queries performed on $G_{sf10}$ and $G_{sf30}$ are from SNB-M.

The other benchmark is Join Order Benchmark (JOB) \cite{job_snb} on Internet Movie Database (abbr.~IMDB).
Specifically, IMDB is a dataset mainly about the relationships among movies, persons, and movie companies.
JOB focuses on the problem of join order optimization, and queries in JOB have an average of 8 joins.
The details of the datasets are summarized in Table \ref{table:experiment-datasets}, where |V| and |E| represent the number of vertices and edges in the datasets, respectively.
For IMDB, its tables are regarded as vertices or edges first, and then the number of vertices and edges are counted.

\textbf{Baselines. }
In the experiments, two optimizers of type $Rel$ and $Rel^+$ respectively are utilized as the baselines.
Specifically, the opitmizer of type $Rel$ is that of DuckDB, which is a well-known open-source database.
The version of DuckDB is 0.9.2.
The optimizer of type $Rel^+$ is that of GrainDB.
It optimizes queries with the optimizer of DuckDB first, and then replaces some hash joins in the obtained physical plans with sip joins or merge sip joins.
To ensure the fairness of the comparison, we first upgrade the version of DuckDB that is integrated into GrainDB to 0.9.2.
Then, given a query, after a physical plan w.r.t.~this query is obtained by an optimizer, the plan is transformed to that of GrainDB.
Therefore, different plans can be executed by the the backend, and the efficiency of the plans obtained by varied optimizers can be compared fairly.
Please note that codegen techniques can be employed to facilitate the transformation of the physical plan.
For simplicity, in the rest of this paper, when there is no ambiguity, the optimizers of DuckDB and GrainDB are shortened to DuckDB and GrainDB, respectively.

Our experiments are carried out on a server with Intel Xeon E5-2682 2.50GHz CPU and 251GB RAM.

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/e2e_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-e2e-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/e2e_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-e2e-sf30}
    \end{subfigure}
    \begin{subfigure}[b]{0.6\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/e2e_job.pdf}
        \caption{Time Cost on IMDB.}
        \label{fig:exp-e2e-job}
    \end{subfigure}
    \caption{Results of the end-to-end experiments.}
    \label{fig:exp-e2e}
\end{figure*}

\subsection{End-to-End Experiments}
\label{sec:experiment-e2e}

End-to-end experiments are conducted on SNB-M and JOB benchmarks to compare the performances of execution plans obtained by DuckDB, GrainDB, and relgo.
For experments on the LDBC benchmark, each IC query is executed for 50 times with different times, and the average time cost is reported.
The exeprimental results are shown in Fig.~\ref{fig:exp-e2e}.

The results demonstrate that the execution plans obtained with relgo are always better than those obtained with GrainDB and DuckDB.
For example, when query 1a is queried on the IMDB dataset, executing the plan from relgo is about 6$\times$ and 10$\times$ faster than executing the plans from GrainDB and DuckDB, respectively.
There are mainly two reasons for the superiority of relgo.
Firstly, relgo is aware of the existence of graph indices in graph query optimization.
Thus, the cost estimation of rego is more accurate and better physical plans can be obtained.
In contrast, the optimizers of DuckDB and GrainDB are of the types $Rel$ and $Rel^+$, respectively, and are not aware of the graph indices in query optimization.
Therefore, the accuracy of cost estimation is limited.
Secondly, for queries with cycles (e.g., IC7-1 on SNB-M), relgo can replace multiple joins with extend-intersection.
Such an operator can significantly reduce the time consumption, which is demonstrated through experiments in Sec.~\ref{sec:experiment-circle}.
Thirdly, relgo is more adept at identifying opportunities to effectively utilize graph indices to get neighbors of vertices, since it optimizes graph queries from the graph perspective.
Conversely, GrainDB occasionally partitions the process into separate stages, first retrieving adjacent edges and subsequently obtaining the corresponding endpoints.


\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/pattern-triangle.png}
        \caption{Triangle}
        \label{fig:exp-hard-triangle}
    \end{subfigure}
    \begin{subfigure}[b]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/pattern-butterfly.png}
        \caption{Butterfly}
        \label{fig:exp-hard-butterfly}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/pattern-clique.png}
        \caption{4-Clique}
        \label{fig:exp-hard-clique}
    \end{subfigure}
    \caption{Patterns searched for in case studies.}
    \label{fig:exp-hard-patterns}
\end{figure}

\subsection{Queries with Cycles}
\label{sec:experiment-circle}

Cycles are commonly encountered in practical queries \cite{common-cycle}.
However, few queries in SNB-M and JOB benchmarks contain cycles.
Therefore, for the comprehensiveness of evaluation, we design three SQL/PGQ queries to find the patterns shown in Fig.~\ref{fig:exp-hard-patterns} on $G_{sf10}$ and $G_{sf30}$.
Please note that these patterns all contain cycles.
Take finding 4-cliques as an example, the corresponding SQL/PGQ query is as follows:
\begin{lstlisting}
    SELECT pn1, pn2, pn3, pn4 
    FROM GRAPH_TABLE (knows_grpah
        MATCH (p1:Person)-[:Knows]->(p2:Person)-[:Knows]->(p3:Person)-[:Knows]->(p4:Person),
            (p4)-[:Knows]->(p1)-[:Knows]->(p3),
            (p2)-[:Knows]->(p4)
        COLUMNS (
            p1.id as pn1, p2.id as pn2, 
            p3.id as pn3, p4.id as pn4
        )
    );
\end{lstlisting}
With these three queries, the efficiency of the physical plans obtained by relgo and those obtained by GrainDB are compared.
The experimental results are shown in Fig.~\ref{fig:exp-hard}.


\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/hard_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-hard-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/hard_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-hard-sf30}
    \end{subfigure}
    \caption{Experiments on the time cost of finding patterns in Fig.~\ref{fig:exp-hard-patterns} on $G_{sf10}$ and $G_{sf30}$.}
    \label{fig:exp-hard}
\end{figure}

The experimental results indicate the superiority of relgo compared with GrainDB.
In detail, the physical plans obtained by relgo are always much better than those obtained by GrainDB.
Under the best conditions, i.e., the 4-clique pattern queried on $G_{sf30}$, the execution time of the plan optimized with relgo can be more than an order of magnitude shorter than that of GrainDB.
Such a significant improvement comes from relgo's more accurate estimation of cost, and a better plan can be generated.
Besides, \expandintersectrule can be utilized in the plan generated with relgo, and it is much more efficient than performing multiple joins as illustrated in Sec.~\ref{sec:experiment-ablation}.



\subsection{Ablation Study}
\label{sec:experiment-ablation}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/ablation_ei_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-ablation-ei-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/ablation_ei_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-ablation-ei-sf30}
    \end{subfigure}
    \caption{Abaltion study on \expandintersectrule. Please note that executing plans obtained with "Relgo w.o. EI" to find bufferflies and 4-cliques triggers an ``Out of Memory'' (abbr.~OOM) error.}
    \label{fig:exp-ablation-ei}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/ablation_ei_para_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-ablation-para-ei-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/ablation_ei_para_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-ablation-para-ei-sf30}
    \end{subfigure}
    \caption{Abaltion study on \expandintersectrule with constrained-patterns. Specifically, the patterns \textit{``Butterfly-P''} and \textit{``4-Clique-P''} are generated by adding predicates on properties Person1.\textit{p\_personid} to \textit{``Butterfly''} (Fig.~\ref{fig:exp-hard-butterfly}) and \textit{``4-Clique''} (Fig.~\ref{fig:exp-hard-clique}).
    The predicates require the values of \textit{p\_personid} to be smaller than specified values and are utilized to avoid OOM.}
    \label{fig:exp-ablation-para-ei}
\end{figure}

In this section, we conduct ablation study to show the efficiency of \expandintersectrule.
In detail, patterns in Fig.~\ref{fig:exp-hard-patterns} are queried on $G_{sf10}$ and $G_{sf30}$, and plans are optimized with Relgo.
For each plan optimized by Relgo, we replace the extend-intersect operators in it with multiple join operators and obtain a new plan.
These new plans are called obtained with \textit{"Relgo w.o. EI"}.
The experimental results are shown in Fig.~\ref{fig:exp-ablation-ei}.

The results illustrate the efficiency of \expandintersectrule.
When triangles are searched for, removing the extend-intersect operators decreases the query performance.
Besides, when butterflies and 4-cliques are searched for, the plans without extend-intersect operators have an excessive memory overhead and cause an ``Out of Memory'' (abbr.~OOM) error.
The reason is that applying extend-intersect operators has much fewer intermediate results than applying multiple joins, since numerous results that will not appear in the intersection are prematurely deleted.
It indicates that \expandintersectrule can not only enhance query performance, but also reduce spatial overhead.

To further demonstrate the efficiency of \expandintersectrule, we add predicates on butterflies (i.e., Fig.~\ref{fig:exp-hard-butterfly}) and 4-cliques (i.e., Fig.~\ref{fig:exp-hard-clique}) to avoid OOM, and generate two new patterns, i.e., \textit{Butterfly-P} and \textit{4-Clique-P}. 
Specifically, for these two new patterns, the values of properties Person1.\textit{p\_personid} are constrained to be smaller than specified values.
Queries of these new patterns are optimized with GrainDB, relgo, and \textit{relgo w.r. EI}.
The results on the constrained-patterns are shown in Fig.~\ref{fig:exp-ablation-para-ei}.


The results suggest that \expandintersectrule is crucial in optimizing queries with cycles.
Specifically, for the new patterns with cycles, the execution time of plans optimized by relgo is more than an order of magnitude shorter than those optimized by \textit{"Relgo w.o. EI"}.
It indicates the effectiveness of \expandintersectrule.
Moreover, when patterns with many cycles are used (e.g., 4-clique in Fig.~\ref{fig:exp-hard-clique}), the optimization effect of the rule becomes particularly noticeable.
In detail, querying for 4-cliques with relgo can be 100$\times$ faster than with \textit{"Relgo w.o. EI"}.
The results illustrate the efficiency of \expandintersectrule.


%\subsection{Detailed Evaluation}
%\label{sec:experiment-detail}

%time cost of index building
%compilation
%query execution

\subsection{Optimization Efficiency Evaluation}
\label{sec:experiment-optimize}

In this subsection, experiments are conducted to compare the optimization time cost of relgo and Apache Calcite, which is a well-known data management framework widely used in various projects such as Hive and Kylin.
Please note that the codes of relgo and Calcite are both written in Java.
In detail, we test the optimization time of relgo and Calcite on SNB-M and JOB benchmarks, and VolcanoPlanner of Calcite with default rules is leveraged.
If optimization for a query is not finished in 10 minutes, the process is early stopped and the time cost of such optimization is recorded as 10 minutes.
The results are shown in Fig.~\ref{fig:exp-optimization}.

\begin{figure*}[ht]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/optimization_sf10.pdf}
        \caption{Optimization Time Cost on $G_{sf10}$.}
        \label{fig:exp-optimization-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/optimization_sf30.pdf}
        \caption{Optimization Time Cost on $G_{sf30}$.}
        \label{fig:exp-optimization-sf30}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/optimization_job.pdf}
        \caption{Optimization Time Cost on IMDB.}
        \label{fig:exp-optimization-job}
    \end{subfigure}
    \caption{Experiments on the time cost of optimization.}
    \label{fig:exp-optimization}
\end{figure*}

In the experiments, optimizing all the queries with relgo can be finished in 10 minutes, while optimizing some queries with Calcite exceeds the 10-minute limit.
For example, when JOB benchmark is utilized, the time cost of optimizing all the queries with Calcite is longer than 10 minutes.
As shown in Fig.~\ref{fig:exp-optimization}, relgo is much more efficient than Calcite in optimizing queries, and it is consistent with the conclusions obtained in Sec.~\ref{sec:theoretical-analysis}.
That is, relgo is exponentially faster than Calcite in query optimization.
For instance, when IC5-1 is queried on $G_{sf30}$, the time cost of query optimization with relgo can be more than $10^4\times$ faster than that of Calcite.

Besides, the optimization time cost of relgo is similar on $G_{sf10}$ and $G_{sf30}$, and so is Calcite.
The reason is that the time required for optimization is not significantly associated with the scale of the dataset; instead, it is related to the relative cardinalities among the different tables.
The relative cardinalities in LDBC datasets of different scales are consistent, therefore the optimization time is similar.


\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/filter_sf10.pdf}
        \caption{Time Cost on $G_{sf10}$.}
        \label{fig:exp-filter-sf10}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./figures/exp/filter_sf30.pdf}
        \caption{Time Cost on $G_{sf30}$.}
        \label{fig:exp-filter-sf30}
    \end{subfigure}
    \caption{Comparison of efficiency between relgo and \textit{relgo w.o. inter}.}
    \label{fig:exp-filter}
\end{figure}

\subsection{Efficiency of Optimizations across Relational and Graph Queries}
\label{sec:experiment-case-study}

To demonstrate the efficiency of relgo compared to $Rel+G$ optimizers, we remove the optimizations across the relational and graph subplans and generate a new $Rel+G$ optimizer named \textit{relgo w.o.~inter}.
Then, experiments are conducted on SNB-M benchmark and seven typical queries are chosen, i.e., IC2-1, IC6-1, IC6-2, IC9-1, IC9-2, IC11-1, and IC11-2.
These queries are chosen because they have constraints on the output values.
Therefore, users might write some SQL/PGQ queries where the graph query portion performs pattern matching, and the relational query portion filters the results of the graph query.
For each of these chosen queries (e.g., IC2-1), the corresponding SQL/PGQ query is generated (i.e., SP2-1).
For example, SP2-1 is as follows:
\begin{lstlisting}
    SELECT p_id, p_fn, p_ln, c_id, c_ct, c_creationDate
    FROM GRAPH_TABLE (ldbc_graph
        MATCH (p1:PERSON {id:$personId})-[:KNOWS]->(p2:PERSON)<-[:HASCREATOR]-(c:COMMENT)
        COLUMNS (p2.id as p_id, p2.firstName as p_fn,
            p2.lastName as p_ln, c.id as c_id,
            c.content as c_ct, c.creationDate as c_creationDate
        )
    )
    WHERE c_creationDate < $creationDate;
\end{lstlisting}
Experiments are conducted on $G_{sf10}$ and $G_{sf30}$ to compare the efficiency of relgo and \textit{relgo w.o.~inter} and the results are shown in Fig.~\ref{fig:exp-filter}.


The results suggest that relgo always has better performances than \textit{relgo w.o.~inter}, which illustrates the efficiency of the optimizations across the relational and graph subplans.
In detail, when SP2-1 is queried on $G_{sf30}$, the execution time of plans obtained with \textit{relgo w.o.~inter} is longer than twice that of plans obtained with relgo.

Please note that relgo and \textit{relgo w.o.~inter} have similar performances on some queries, e.g., SP6-1 and SP11-1.
The reason is that \filterrule is primarily in effect in these queries.
However, the pruning effect induced by constraints delineated within the relational query portion is comparatively marginal, while the pruning effect of the other constraints within the graph query portion is highly effective.
Consequently, whether to apply \filterrule to push the filter constraints down into graph queries has limited influence in these queries.

\subsection{Efficiency of the Join Order}
\label{sec:experiment-efficiency-of-plans}

In this section, we propose experiments to show the efficiency of the join orders generated by relgo.
In detail, for the plans generated with relgo, we replace the join operators using graph indices with hash joins.
The newly obtained plans are said to be generated by an optimizer named relgo-hash.
Please note that graph indices are not utilized when the plans generated by relgo-hash are executed.
Specifically, the performances of relgo and relgo-hash are compared in this subsection on JOB benchmark.
Without loss of generality, queries job1a--job10a are utilized as the representatives in the experiments.
The experimental results are shown in Fig.~\ref{fig:exp-hash-plan}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.9\linewidth]{./figures/exp/hash_plan_job.pdf}
    \caption{Experiments that compare the efficiency of relgo and relgo-hash.}
    \label{fig:exp-hash-plan}
\end{figure}

As shown in Fig.~\ref{fig:exp-hash-plan}, the execution time of plans generated by relgo-hash is always longer than those generated by relgo.
It demonstrates using graph indices can enhance query performance,
Besides, the plans optimized with relgo-hash are always not inferior to those optimized by DuckDB.
It suggests that even if graph indices cannot be applied in execution, the plans optimized with relgo are still efficient.
It is noteworthy that when queries job4a and job5a are executed, the completion time for the plans generated by relgo-hash is shorter than that for the plans produced by GrainDB. 
It is important to highlight that while graph indices are employed in executing GrainDB's plans, they are not utilized with relgo-hash's plans. The underlying reason for the superiority of relgo-hash's plans is that it can determine a more effective join order, owing to its awareness of higher-order statistics. 
This superior join order offsets the absence of graph indices in the execution process.
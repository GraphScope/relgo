\section{Superiority of the Graph Optimizer on Graph Queries}
\label{sec:theoretical-analysis}

In this section, we prove that graph optimizers have better performance than relational optimizers.
Besides, since graph optimizers cannot always be used to optimize relational queries, it confirms the necessity of proposing the converged query optimization.

As one of the most widely adopted optimizers for relational databases, we use Calcite \cite{calcite,columbia} as a representative of relational JOPTs and analyze its efficiency of join order optimization.
For the converged JOPT, we use GLogue \cite{GLogS} as the graph JOPT, and integrate it with Calcite.

A more simple condition is first considered.
That is, all the tables in the query can represent vertices or edges.
Then, it is supposed that there are $n + m$ tables are joined together, where $n$ tables represent vertices while $m$ tables represent edges.
Suppose that there are $t$ implementation methods for join.
The complexities of optimizing the join order with Calcite and the converged JOPT are analyzed respectively as follows.
For simplicity, the time complexities are evaluated by the number of physical plans generated by the JOPTs.

\begin{theorem}
    \label{theorem:complexity-of-calcite}
    The time complexity of join order optimization with Calcite is at least $O(\frac{4^{m+n-1}}{m+n}t^{m+n-1})$.
\end{theorem}
\begin{proof}
    The $n + m$ tables joined together can form a graph, where the tables represent vertices in the graph, and if there is a join condition specifying the equivalence of two columns in two two tables, there is an edge between these two tables.
    Then, the complexity of join order optimization with Calcite can be estimated as the number of possible physical plans that can be generated.
    
    To avoid cross product, except for the first table, the selected tables to be be joined with the already chosen tables should be neighbors of the chosen tables in the graph.
    Therefore, the join order can be represented as a spanning tree in the graph.
    By computing the number of physical plans can be generated according to each spanning tree, the total number of physical plans can be obtained.
    However, same phyical plans may be obtained according to different spanning trees.
    For example, suppose a graph is a rectangle with four vertices and four edges.
    It may be constructed for a query like:
    \begin{equation*}
        \begin{split}
            \text{SELECT}\hspace{.5em} ... & \hspace{.5em}\text{FROM}\hspace{.5em} A, B, C, D \hspace{.5em}\text{WHERE}\hspace{.5em} A.a1 = B.b1 \\ 
            & \hspace{.5em}\text{AND}\hspace{.5em} B.b2 = C.c1 \hspace{.5em}\text{AND}\hspace{.5em} C.c2 = D.d1 \hspace{.5em}\text{AND}\hspace{.5em} D.d2 = A.a2. 
        \end{split}
    \end{equation*}
    Then, the spanning tree with edges \{AB, BC, CD\} and the one with edges \{AB, BC, AD\} can generate the same physical plans.
    Consequently, the summation of the number of physical plans corresponding to all the spanning trees is larger than the actual number of physical plans.
    In this proof, we compute the number of physical plans for one spanning tree, and this number is the lower bound of the number of physical plans that can be generated.

    Given a spanning tree with $k$ edges (i.e., $k+1$ vertices representing tables) and only one leaf node, the number of logical plans corresponding to the spanning tree is roughly
    \begin{equation*}
        \begin{split}
            c(k) & = 2 * (c(0)c(k-1) + c(1)c(k-2) + \cdots + c(k-1)c(0)) \\
            & = 2\Sigma_{i=0}^{i=k-1}c(i)c(k-1-i), \\
            & \text{where } c(0) = 1.
        \end{split}
    \end{equation*}
    With the generating function, it is obtained that 
    \begin{equation*}
        c(k) = \frac{2^k}{k+1}C(2k, k).
    \end{equation*}
    Since $k$ is the number of edges, and $k = m + n - 1$ in the spanning tree.
    Thus, the number of logical plans w.r.t.~a spanning tree is 
    \begin{equation*}
        \frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1) \geq \frac{4^{m+n-1}}{m+n}.
    \end{equation*}
   Then, the number of physical plans is at least $\frac{4^{m+n-1}}{m+n}t^{m+n-1}$, so is the complexity of join order optimization with Calcite.
   
   In conclusion, Theorem \ref{theorem:complexity-of-calcite} is correct.
\end{proof}

\begin{lemma}
    \label{lemma:upper-bound-of-calcite}
    Given $n$ tables, the time complexity of join order optimization with Calcite has an upper bound of $O(\frac{(2n-2)!}{(n-1)!}t^{n-1})$.
\end{lemma}
\begin{proof}
    The upper bound of the time complexity of join order optimization is achieved when there is a condition between any two of the $n$ tables.
    Because at that time, the tables can be joined in any order.

    Since each join order corresponds to a full binary tree with $2n-1$ nodes, the problem is to count the number of possible full binary trees.
    Similar to Catalan number, the number of full binary trees is $O(C(2n-2, n-1) - C(2n-2, n))$.
    For each full binary tree, there are $n!$ ways to set the leaf nodes. 
    Then, the number of generated physical plans is $O(\frac{(2n-2)!}{(n-1)!}t^{n-1})$.
\end{proof}

\begin{theorem}
    \label{theorem:complexity-of-glogue}
    The time complexity of join order optimization with the converged JOPT is smaller than $3^n$ if all the tables participant in join can represent vertices or edges.
\end{theorem}
\begin{proof}
    Since the $n + m$ tables represent vertices and edges respectively and the join among them can be represented as a graph query, the converged JOPT optimizes the join order with the graph optimizer, i.e., GLogue.

    As GLogue ensures worst-case optimality and the considered patterns are all induced subgraphs, the time complexity of join order optimization with GLogue is not related to the number of edges (i.e., $m$).
    Because JOOP is reduced to a variant of shortest path problem, the time complexity of join order optimization is $O(\mathcal{E})$, where $\mathcal{E}$ is the number of edges in GLogue.
    In detail, 
    \begin{equation*}
        \begin{split}
            O(\mathcal{E}) & = C(n, n-1)*(2^{n-1}-1) + C(n, n-2) * (2^{n-2}- 1) \\
            & + \cdots + C(n, 1) * (2^1 - 1) \\
            & = 3^n - 2^{n+1} +1 \\
            & < 3^n.
        \end{split}
    \end{equation*}
    
    In conclusion, Theorem \ref{theorem:complexity-of-glogue} is correct.

\end{proof}

Based on the complexity analysis in Theorem \ref{theorem:complexity-of-calcite} and Theorem \ref{theorem:complexity-of-glogue}, it is found that when the tables represent vertices and edges, 
\begin{equation*}
    \begin{split}
        \frac{\text{Time Complexity of Calcite}}{\text{Time Complexity of the Converged JOPT}} & = \frac{\frac{4^{m+n-1}}{m+n}}{3^n}t^{m+n-1} \\
        & \geq 2^{m-3}(\frac{4}{3})^nt^{m+n-1}.
    \end{split}
\end{equation*}
Therefore, it suggests that the converged JOPT is exponentially faster than Calcite for graph-like join order optimization.
The results also indicates that integrating graph optimizers into relational optimizers can improve the efficiency of join order optimization significantly.


Then, if there are some tables that cannot represent vertices or edges, the order of such tables cannot be optimized with graph optimizers, and the comparion becomes more complicate.
For example, suppose five tables form a clique, and then these tables cannot be vertices or edges in a graph.
Specifically, according to the dataflow shown in Fig.~\ref{fig:dataflow}, the join order of these left tables are optimzed by relational optimizers such as Calcite.
Let the number of left tables be $s$, and together with the table obtained by the join of the tables optimized with graph optimizer, Calcite needs to optimize the join order among $s + 1$ tables.

When $s = 0$, all the tables represent vertices or edges, and the time complexity of the converged JOPT is exponentially smaller than that of Calcite as analyzed as above.

When $s = 1$, only one table (saying $T_1$) does not represent a vertex or an edge, and Calcite optimizes the join between two tables.
One of these two tables is $T_1$, and the other is the table obtained by the join of the tables optimized with graph optimizer.
Then, we have
\begin{equation*}
    \begin{split}
        \frac{\text{Time Complexity of Calcite}}{\text{Time Complexity of the Converged JOPT}} > \hspace{-12em} & \\
        & \frac{\frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1)t^{m + n - 1}}{3^{\hat{n}} + \frac{(2s)!}{(s)!}t^{s}} \\
        & = \frac{\frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1)t^{m + n - 1}}{3^{\hat{n}} + 2} >> 1,
    \end{split}
\end{equation*}
where $\hat{n}$ is the number of tables representing vertices.
It indicates the superiority of the converged JOPT.

When $s = m + n - 1$ or $p = m + n$, at most one table can represent vertices or edges, and the converged JOPT degenerates to Calcite, and has the same efficiency as it.
A typical example is when there is a condition between any two of these $m + n$ tables.

The results show that the converged JOPT is always superior to relational JOPTs.
To be more specific, we prove the superiority of the converged JOPT more theoretically.

\begin{lemma}
    \label{lemma:join-spliter}
    Let $\text{JN}_c(V_s)$ represent the number of possible physical plans of joining tables in table set $V_s$ with Calcite.
    Suppose $n$ tables (denoted as table set $V$) are joined, and $V = (V_1 - u) \cup V_2$, $V_1 \cap V_2 = \emptyset$.
    Specifically, $u \in V_1$ is a table representing the results of joining the tables in $V_2$.
    For each table $t_2 \in V_2$, if there is a join condition between $t_2$ and a table $v$ in $V_1$, the same join condition exists between $u$ and $v$.
    Then, we have $\text{JN}_c(V) \geq \text{JN}_c(V_1) * \text{JN}_c(V_2)$.
\end{lemma}
\begin{proof}
    For a physical plan generated by joining tables in $V_1$ (denoted as $p_1$) and a plan generated by joining tables in $V_2$ (denoted as $p_2$), by replacing $u$ in $p_1$ with $p_2$, we can generate a physical plan of joining tables in in $V$.
    Besides, since the tables in $p_1$ cannot be interchanged with tables in $p_2$, more physical plans can be generated by joining tables in $V$.
    In conclusion, we have $\text{JN}_c(V) \geq \text{JN}_c(V_1) * \text{JN}_c(V_2)$.
\end{proof}

\begin{theorem}
    \label{theorem:complexity-of-converged-jopt}
    The time complexity of join order optimization with the converged JOPT is always smaller than that with Calcite.
\end{theorem}
\begin{proof}
    Denote the set of tables that cannot represent vertices and edges by $S$.
    Besides, denote the set of tables that represent vertices and edges by $R$, and denote the table obtained by joining the tables in $R$ by $T_r$.
    Then, we have $S_r = S \cup T_r$.
    Moreover, let $s = |S|$ and $r = |R|$ represent the size of tables set $S$ and $R$, respectively, and let $s_v$ be the number of tables in $S$ representing vertices.
    Denote the number of possible physical plans of joining tables in $R$ with GLogue by $\text{JN}_g(R)$.
    
    Specifically, according to Theorem \ref{theorem:complexity-of-calcite} and Theorem \ref{theorem:complexity-of-glogue}, we have $\text{JN}_g(R) < 3^{s_v} \leq \frac{4^{r-1}}{r}t^{r-1} \leq \text{JN}_c(R)$.
    Note that $T_r$ corresponds to $u$ in Lemma \ref{lemma:join-spliter}.
    Based on Lemma \ref{lemma:join-spliter}, we have $\text{JN}_c(S \cup R) \geq \text{JN}_c(S_r) * \text{JN}_c(R) \geq \text{JN}_c(S_r) * \text{JN}_g(R)$.
    In conclusion, Theorem \ref{theorem:complexity-of-converged-jopt} is correct, and the converged JOPT always has smaller time complexity than Calcite.
\end{proof}

There are mainly three reasons contributing to the efficient performance of the converged JOPT:
(1) Different implementations of the join operators are not considered in the converged JOPT, because the neighbors of vertices can be efficiently accessed with the graph indices.
(2) In the converged JOPT, only the number of vertices influence the complexity of join order optimization, while the complexity is determined by both the numbers of vertices and edges in Calcite.
(3) The converged JOPT can take isomorphism into consideration in optimization and further reduce the search space, while Calcite does not consider optimization related to isomorphism.
